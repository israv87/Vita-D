# -*- coding: utf-8 -*-
"""Regresion Logistica VITA-D.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RZUVF_kMtryAHcDoXuyW_BArCSgejWdj

# Ejercicio Python de Regresión Logística
Realizaremos un ejercicio de prueba para comprender como funciona este algoritmo
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn import linear_model
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sb
# %matplotlib inline

"""## Cargamos los datos de entrada del archivo csv"""

dataframe = pd.read_csv(r"/content/BDSeleccionadaV3.csv")
dataframe.head()

dataframe.describe()

import matplotlib.pyplot as plt
import seaborn as sns

# Configurando el estilo de los gráficos
sns.set(style="whitegrid")

# Creando la figura y el eje para el gráfico
fig, ax = plt.subplots(figsize=(10, 6))

# Gráfico de distribución de los niveles de Vitamina D
sns.histplot(dataframe['VitaminaD'], bins=30, kde=True, ax=ax)

ax.set_title('Distribución de los Niveles de Vitamina D')
ax.set_xlabel('Niveles de Vitamina D')
ax.set_ylabel('Frecuencia')

plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Tu código existente para actualizar la categoría de Vitamina D
def categorizar_vitamina_d_binario(valor):
    if valor < 18:
        return 0
    #elif valor < 20:
    #    return 1
    else:  # Valores iguales o superiores a 18 se marcan como 1, incluyendo los superiores a 35
        return 2

dataframe['CategoriaVitaD'] = dataframe['VitaminaD'].apply(categorizar_vitamina_d_binario)
dataframe['CategoriaVitaD'] = dataframe['CategoriaVitaD'].astype(int)
#print(dataframe.head())

# Ahora, generamos la gráfica para visualizar la distribución de los datos en 'CategoriaVitaD'
plt.figure(figsize=(8, 6))  # Ajusta el tamaño de la gráfica
sns.countplot(x='CategoriaVitaD', data=dataframe)  # Creamos una gráfica de barras con Seaborn
plt.title('Distribución de los Niveles de Vitamina D Categorizados')  # Título de la gráfica
plt.xlabel('Categoría de Vitamina D')  # Etiqueta del eje X
plt.ylabel('Conteo')  # Etiqueta del eje Y
plt.show()  # Muestra la gráfica

print(dataframe.groupby('CategoriaVitaD').size())

"""## Visualizamos los datos"""

dataframe.drop(['CategoriaVitaD'],1).hist()
plt.show()

#sb.pairplot(dataframe.dropna(), hue='clase',size=4,vars=["duracion", "paginas","acciones","valor"],kind='reg')

"""## Creamos el modelo"""

X = np.array(dataframe.drop(['CategoriaVitaD', 'VitaminaD'],1))
y = np.array(dataframe['CategoriaVitaD'])
X.shape

model = linear_model.LogisticRegression()
model.fit(X,y)

predictions = model.predict(X)
print(predictions)

model.score(X,y)

"""# Adicional: Validación del Modelo"""

validation_size = 0.20
seed = 7
X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, y, test_size=validation_size, random_state=seed)

name='Logistic Regression'
kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=seed)
cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')

predictions = model.predict(X_validation)
msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
print(msg)

"""## Reporte de Resultados"""

print(confusion_matrix(Y_validation, predictions))

accuracy = accuracy_score(y_true=Y_validation, y_pred=predictions, normalize=True)
print(f"El accuracy de test es: {100 * accuracy} % \n")
print(classification_report(Y_validation, predictions))

"""# Clasificación de nuevos registros"""